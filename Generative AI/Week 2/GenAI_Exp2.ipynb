{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4a2891c6",
      "metadata": {
        "id": "4a2891c6"
      },
      "source": [
        "# GAN on MNIST (PyTorch)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, utils\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# CONFIG\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "lr = 0.0002\n",
        "batch_size = 128\n",
        "epochs = 50  # Increased for better convergence\n",
        "noise_dim = 100\n",
        "real_label_val = 0.9  # Label Smoothing (Key improvement)\n",
        "\n",
        "print(f\"Device: {device}\")\n",
        "os.makedirs(\"results\", exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F7KpYwimtFH",
        "outputId": "3a466ca4-bced-4739-8350-c1dccb41c670"
      },
      "id": "1F7KpYwimtFH",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DATASET\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)) # Normalize to [-1, 1] for Tanh\n",
        "])\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    datasets.MNIST(\"./data\", train=True, download=True, transform=transform),\n",
        "    batch_size=batch_size, shuffle=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JmNcljBmtaT",
        "outputId": "3e2c7b72-7b65-449b-ec4d-f4fc1c83bf16"
      },
      "id": "2JmNcljBmtaT",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.7MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 504kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.72MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 16.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MODELS\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(noise_dim, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(1024, 28*28),\n",
        "            nn.Tanh() # Output range [-1, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x).view(-1, 1, 28, 28)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# INIT\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "opt_G = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "opt_D = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "ttWB1_ZymwBi"
      },
      "id": "ttWB1_ZymwBi",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING\n",
        "for epoch in range(epochs):\n",
        "    for real_imgs, _ in dataloader:\n",
        "        real_imgs = real_imgs.to(device)\n",
        "        bs = real_imgs.size(0)\n",
        "\n",
        "        # Labels (Smoothing applied to real labels)\n",
        "        real_labels = torch.full((bs, 1), real_label_val, device=device)\n",
        "        fake_labels = torch.zeros((bs, 1), device=device)\n",
        "\n",
        "        # --- Train Discriminator ---\n",
        "        opt_D.zero_grad()\n",
        "\n",
        "        # Real loss\n",
        "        out_real = D(real_imgs)\n",
        "        loss_real = criterion(out_real, real_labels)\n",
        "\n",
        "        # Fake loss\n",
        "        z = torch.randn(bs, noise_dim, device=device)\n",
        "        fake_imgs = G(z)\n",
        "        out_fake = D(fake_imgs.detach()) # Detach to avoid G gradients\n",
        "        loss_fake = criterion(out_fake, fake_labels)\n",
        "\n",
        "        loss_D = loss_real + loss_fake\n",
        "        loss_D.backward()\n",
        "        opt_D.step()\n",
        "\n",
        "        # --- Train Generator ---\n",
        "        opt_G.zero_grad()\n",
        "\n",
        "        # Generator aims for real labels (1.0) to trick D\n",
        "        # We use standard 1.0 here for G target, or reuse smoothed 0.9\n",
        "        out_gen = D(fake_imgs)\n",
        "        loss_G = criterion(out_gen, torch.ones((bs, 1), device=device))\n",
        "\n",
        "        loss_G.backward()\n",
        "        opt_G.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Loss D: {loss_D.item():.4f} | Loss G: {loss_G.item():.4f}\")\n",
        "\n",
        "    # Save progress\n",
        "    if (epoch+1) % 5 == 0:\n",
        "        utils.save_image(fake_imgs, f\"results/epoch_{epoch+1}.png\", normalize=True)\n",
        "\n",
        "# Final Save\n",
        "z = torch.randn(64, noise_dim, device=device)\n",
        "utils.save_image(G(z), \"results/final_grid.png\", normalize=True)\n",
        "print(\"Training Complete. Images saved to 'results/' folder.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UW0k0vpbmzBH",
        "outputId": "5c5bb351-18fa-44b9-db02-3711237865b9"
      },
      "id": "UW0k0vpbmzBH",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 | Loss D: 1.7329 | Loss G: 2.4440\n",
            "Epoch 2/50 | Loss D: 0.7515 | Loss G: 1.8923\n",
            "Epoch 3/50 | Loss D: 1.1124 | Loss G: 1.1669\n",
            "Epoch 4/50 | Loss D: 0.9086 | Loss G: 2.1398\n",
            "Epoch 5/50 | Loss D: 1.0319 | Loss G: 1.3179\n",
            "Epoch 6/50 | Loss D: 0.9729 | Loss G: 1.0665\n",
            "Epoch 7/50 | Loss D: 0.9634 | Loss G: 1.3798\n",
            "Epoch 8/50 | Loss D: 0.9208 | Loss G: 1.2606\n",
            "Epoch 9/50 | Loss D: 0.8973 | Loss G: 1.3619\n",
            "Epoch 10/50 | Loss D: 0.8658 | Loss G: 1.7379\n",
            "Epoch 11/50 | Loss D: 1.0753 | Loss G: 1.5761\n",
            "Epoch 12/50 | Loss D: 1.0968 | Loss G: 1.1694\n",
            "Epoch 13/50 | Loss D: 1.1335 | Loss G: 1.2689\n",
            "Epoch 14/50 | Loss D: 1.1684 | Loss G: 1.7083\n",
            "Epoch 15/50 | Loss D: 1.1969 | Loss G: 0.9695\n",
            "Epoch 16/50 | Loss D: 1.1457 | Loss G: 1.1068\n",
            "Epoch 17/50 | Loss D: 1.2825 | Loss G: 1.6322\n",
            "Epoch 18/50 | Loss D: 1.2308 | Loss G: 1.5759\n",
            "Epoch 19/50 | Loss D: 1.2695 | Loss G: 1.2852\n",
            "Epoch 20/50 | Loss D: 1.2600 | Loss G: 0.9970\n",
            "Epoch 21/50 | Loss D: 1.2777 | Loss G: 0.9447\n",
            "Epoch 22/50 | Loss D: 1.2429 | Loss G: 0.8552\n",
            "Epoch 23/50 | Loss D: 1.1894 | Loss G: 1.1863\n",
            "Epoch 24/50 | Loss D: 1.1641 | Loss G: 1.1749\n",
            "Epoch 25/50 | Loss D: 1.1951 | Loss G: 0.9536\n",
            "Epoch 26/50 | Loss D: 1.2390 | Loss G: 1.3203\n",
            "Epoch 27/50 | Loss D: 1.2404 | Loss G: 0.9555\n",
            "Epoch 28/50 | Loss D: 1.3151 | Loss G: 1.3680\n",
            "Epoch 29/50 | Loss D: 1.1773 | Loss G: 1.0326\n",
            "Epoch 30/50 | Loss D: 1.2364 | Loss G: 1.2952\n",
            "Epoch 31/50 | Loss D: 1.2077 | Loss G: 0.9707\n",
            "Epoch 32/50 | Loss D: 1.2045 | Loss G: 1.1883\n",
            "Epoch 33/50 | Loss D: 1.2076 | Loss G: 1.0786\n",
            "Epoch 34/50 | Loss D: 1.2512 | Loss G: 1.0358\n",
            "Epoch 35/50 | Loss D: 1.3603 | Loss G: 1.6401\n",
            "Epoch 36/50 | Loss D: 1.1860 | Loss G: 0.9851\n",
            "Epoch 37/50 | Loss D: 1.2510 | Loss G: 1.2079\n",
            "Epoch 38/50 | Loss D: 1.1594 | Loss G: 1.2233\n",
            "Epoch 39/50 | Loss D: 1.2625 | Loss G: 0.7584\n",
            "Epoch 40/50 | Loss D: 1.2027 | Loss G: 0.9538\n",
            "Epoch 41/50 | Loss D: 1.2259 | Loss G: 1.1019\n",
            "Epoch 42/50 | Loss D: 1.1811 | Loss G: 1.0794\n",
            "Epoch 43/50 | Loss D: 1.1777 | Loss G: 1.3960\n",
            "Epoch 44/50 | Loss D: 1.2642 | Loss G: 0.8878\n",
            "Epoch 45/50 | Loss D: 1.2653 | Loss G: 1.3692\n",
            "Epoch 46/50 | Loss D: 1.1347 | Loss G: 1.4162\n",
            "Epoch 47/50 | Loss D: 1.1758 | Loss G: 0.9926\n",
            "Epoch 48/50 | Loss D: 1.1733 | Loss G: 1.0111\n",
            "Epoch 49/50 | Loss D: 1.1901 | Loss G: 1.3576\n",
            "Epoch 50/50 | Loss D: 1.1918 | Loss G: 0.9868\n",
            "Training Complete. Images saved to 'results/' folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W_IDNIy5m1kX"
      },
      "id": "W_IDNIy5m1kX",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}